{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZflJMHzqm0zT"
      },
      "source": [
        "If you're opening this Notebook on colab, you will need to clone the repo and change directory. Uncomment the cell below and run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqGXpJ6Vm0zV"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/jbergq/transformer.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoJqRYgypLE7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if Path.cwd().name != \"transformer\":\n",
        "  %cd transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1msvJlmNm0zW"
      },
      "outputs": [],
      "source": [
        "%pip install portalocker\n",
        "%pip install -r requirements.txt\n",
        "%pip install -U protobuf # Temp workaround."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVpo2t6O3QHQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_-7Ahq7m0zW"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchtext.functional as F\n",
        "from torchtext.vocab import vocab as tt_vocab\n",
        "from torchtext.datasets import IMDB\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "from src.model.transformer import TransformerDecoder\n",
        "from src.data.preprocess import PreProcess\n",
        "from src.utils import ExperimentLogger, iter_print, epoch_print, load_config\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict\n",
        "\n",
        "cfg = EasyDict({\n",
        "  \"num_epochs\": 100,\n",
        "  \"sequence_length\": 64,\n",
        "  \"batch_size\": 32,\n",
        "  \"lr\": 1e-5,\n",
        "  \"weight_decay\": 0.0005,\n",
        "  \"print_example\": True\n",
        "})"
      ],
      "metadata": {
        "id": "vtLv8mqyR2wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bFIHBBDm0zX"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion, epoch):\n",
        "    train_losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        tgt = batch[\"target\"].to(device)\n",
        "\n",
        "        out = model(tgt)\n",
        "\n",
        "        out_reshape = out.contiguous().view(-1, out.shape[-1])\n",
        "        tgt_reshape = tgt.contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(out_reshape, tgt_reshape)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val = loss.item()\n",
        "        train_losses.append(loss_val)\n",
        "        iter_print(epoch, i, loss_val)\n",
        "\n",
        "    return torch.tensor(train_losses)\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion, epoch):\n",
        "    val_losses = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        tgt = batch[\"target\"].to(device)\n",
        "\n",
        "        out = model(tgt)\n",
        "\n",
        "        out_reshape = out.contiguous().view(-1, out.shape[-1])\n",
        "        tgt_reshape = tgt.contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(out_reshape, tgt_reshape)\n",
        "\n",
        "        loss_val = loss.item()\n",
        "        val_losses.append(loss_val)\n",
        "        iter_print(epoch, i, loss_val)\n",
        "\n",
        "        pred = out.softmax(dim=2).argmax(dim=2)\n",
        "\n",
        "    return torch.tensor(val_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50nBJQLjm0zX"
      },
      "outputs": [],
      "source": [
        "train_dp, val_dp = IMDB(split=(\"train\", \"test\"))\n",
        "\n",
        "# Tokenizer used by GPT-2.\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "vocab = tt_vocab(tokenizer.get_vocab())\n",
        "transform = PreProcess(tokenizer, cfg.sequence_length - 2)  # -2 For BOS and EOS tokens.\n",
        "\n",
        "# Create datapipes for training and validation.\n",
        "# Each datapipe samples a batch and applies preprocessing.\n",
        "train_dp = train_dp.batch(cfg.batch_size).rows2columnar([\"label\", \"text\"])\n",
        "train_dp = train_dp.map(transform)\n",
        "train_dp = train_dp.map(partial(F.to_tensor, padding_value=1), input_col=\"source\")\n",
        "train_dp = train_dp.map(partial(F.to_tensor, padding_value=1), input_col=\"target\")\n",
        "\n",
        "val_dp = val_dp.batch(cfg.batch_size).rows2columnar([\"label\", \"text\"])\n",
        "val_dp = val_dp.map(transform)\n",
        "val_dp = val_dp.map(partial(F.to_tensor, padding_value=1), input_col=\"source\")\n",
        "val_dp = val_dp.map(partial(F.to_tensor, padding_value=1), input_col=\"target\")\n",
        "\n",
        "train_dataloader = DataLoader(train_dp, batch_size=None)\n",
        "val_dataloader = DataLoader(val_dp, batch_size=None)\n",
        "\n",
        "model = TransformerDecoder(len(vocab), cfg.sequence_length, 512, 1024)\n",
        "model = model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, eps=5e-9)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
        "\n",
        "logger = ExperimentLogger(log_dir=\"./experiments\")\n",
        "\n",
        "if cfg.print_example:\n",
        "    batch = next(iter(train_dataloader))\n",
        "    out = model.generate(torch.zeros((1, 1), dtype=torch.long, device=device))\n",
        "\n",
        "    print(\"Example sequence: \", tokenizer.decode(batch[\"target\"][0].numpy()))\n",
        "    print(\"Model output: \", tokenizer.decode(out[0].detach().cpu().numpy()))\n",
        "\n",
        "for epoch in range(cfg.num_epochs):\n",
        "    train_losses = train(model, train_dataloader, optimizer, criterion, epoch)\n",
        "    val_losses = validate(model, val_dataloader, criterion, epoch)\n",
        "\n",
        "    logger.log_params(\n",
        "        {\n",
        "            \"train_loss\": train_losses.mean().item(),\n",
        "            \"val_loss\": val_losses.mean().item(),\n",
        "        },\n",
        "        step=epoch,\n",
        "    )\n",
        "    epoch_print(epoch, val_losses)\n",
        "\n",
        "    out = model.generate(torch.zeros((1, 1), dtype=torch.long, device=device))\n",
        "    print(tokenizer.decode(out[0].detach().cpu().numpy()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzYXaonvHPVl"
      },
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}