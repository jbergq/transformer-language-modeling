{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZflJMHzqm0zT"
      },
      "source": [
        "If you're opening this Notebook on colab, you will need to clone the repo and change directory. Uncomment the cell below and run it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jXz94Ct2e8QG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'transformer'...\n",
            "remote: Enumerating objects: 448, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 448 (delta 101), reused 130 (delta 63), pack-reused 263\u001b[K\n",
            "Receiving objects: 100% (448/448), 1000.29 KiB | 6.76 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jbergq/transformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PJTF2k85dCMX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jonathanb/git/transformer/transformer\n"
          ]
        }
      ],
      "source": [
        "%cd transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1msvJlmNm0zW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install portalocker\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nUhKN11NhNMN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /home/jonathanb/git/transformer/venv/lib/python3.9/site-packages (12.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /home/jonathanb/git/transformer/venv/lib/python3.9/site-packages (from pyarrow) (1.22.4)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the '/home/jonathanb/git/transformer/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy in /home/jonathanb/git/transformer/venv/lib/python3.9/site-packages (1.22.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "Successfully installed numpy-1.26.2\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the '/home/jonathanb/git/transformer/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyarrow\n",
        "%pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AHT4HP5nkhkV"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1337)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'toy-model',\n",
              " 'val_size': 1000,\n",
              " 'max_iters': 600000,\n",
              " 'eval_iters': 100,\n",
              " 'eval_interval': 1000,\n",
              " 'effective_batch_size': 512,\n",
              " 'batch_size': 4,\n",
              " 'grad_accum_steps': 128,\n",
              " 'lr': 0.001,\n",
              " 'warmup_iters': 2000,\n",
              " 'lr_decay_iters': 600000,\n",
              " 'min_lr': 6e-05,\n",
              " 'weight_decay': 0.0005,\n",
              " 'print_example': True}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dataclasses import dataclass, asdict\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Define base config. Partly adopted from nanoGPT by Andrej Karpathy\n",
        "@dataclass\n",
        "class Config:\n",
        "    model_name: str = \"toy-model\"\n",
        "    val_size: int = 1000  # Size of validation set.\n",
        "    max_iters: int = 600000  # Total num training iterations.\n",
        "    eval_iters: int = 100  # Number of evaluation iterations.\n",
        "    eval_interval: int = 1000\n",
        "    effective_batch_size: int = 512\n",
        "    batch_size: int = 4\n",
        "    grad_accum_steps: int = 1\n",
        "    lr: float = 1e-3\n",
        "    warmup_iters: int = 2000\n",
        "    lr_decay_iters: int = 600000  # Should be ~= max_iters per Chinchilla.\n",
        "    min_lr: float = 6e-5  # Minimum lr, should be ~= lr/10 per Chinchilla.\n",
        "    weight_decay: float = 0.0005\n",
        "    print_example: bool = True\n",
        "\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Derive accumulation steps to get target effective batch size.\n",
        "if cfg.effective_batch_size is not None:\n",
        "    cfg.grad_accum_steps = cfg.effective_batch_size // cfg.batch_size\n",
        "\n",
        "if cfg.model_name == \"toy-model\":\n",
        "    cfg.context_size = 64\n",
        "    cfg.hidden_size = 128\n",
        "    cfg.ff_hidden_size = 256\n",
        "    cfg.num_blocks = 4\n",
        "    cfg.num_heads = 4\n",
        "elif cfg.model_name == \"gpt2-small-custom\":\n",
        "    cfg.context_size = 1024\n",
        "    cfg.hidden_size = 768\n",
        "    cfg.ff_hidden_size = 3072\n",
        "    cfg.num_blocks = 12\n",
        "    cfg.num_heads = 12\n",
        "\n",
        "asdict(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's begin by setting up the training and validation datasets. We will use Hugging Face's `datasets` package to prepare and load the WebText dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load WebText dataset in streaming mode. No need to download!\n",
        "dataset = load_dataset(\"openwebtext\", streaming=True)[\"train\"]\n",
        "shuffled_dataset = dataset.shuffle(seed=42, buffer_size=10000)\n",
        "\n",
        "# Split dataset.\n",
        "train_set = shuffled_dataset.skip(cfg.val_size)\n",
        "val_set = shuffled_dataset.take(cfg.val_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we want to convert the dataset from text to a numeric format that our model can work with. This is called *tokenizing* our dataset. Tokens can be thought of as a numeric representation of the smallest meaningful units of language. After tokenizing the dataset, the text will be represented as sequences of integers that are easier for a machine learning model to work with.\n",
        "\n",
        "Since this guide focuses on the transformer itself and not the tokenization, we will use the GPT-2 tokenizer available from Hugging Face's `transformers` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we define a function called `tokenize` for turning our dataset into the inputs and outputs, called `source` and `target` for training the model. We will be training a language model which simply predicts the next token in a sequence given the tokens so far as input. Therefore, `target` sequences will correspond to `source` sequences shifted by one index to the left.\n",
        "\n",
        "TODO describe multiple training examples per sequence and parallel training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "\n",
        "def tokenize(example):\n",
        "    outputs = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,  # Truncate returned token sequences to max_length.\n",
        "        max_length=cfg.context_size + 1,  # Max length of returned token sequences.\n",
        "        return_overflowing_tokens=True,  # Tokenize whole input and split into chunks.\n",
        "        return_length=True,  # Return lengths of chunks.\n",
        "    )\n",
        "\n",
        "    # Create examples.\n",
        "    source_batch = []\n",
        "    target_batch = []\n",
        "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
        "        if length == cfg.context_size + 1:  # Only include full length sequences.\n",
        "            source_batch.append(input_ids[:-1])\n",
        "            target_batch.append(input_ids[1:])  # Note: Target is source shifted by one.\n",
        "\n",
        "    return {\"source\": source_batch, \"target\": target_batch}\n",
        "\n",
        "\n",
        "# Tokenize train and val sets.\n",
        "train_tokenized = train_set.map(\n",
        "    partial(tokenize),\n",
        "    batched=True,\n",
        "    remove_columns=train_set.column_names,\n",
        ")\n",
        "val_tokenized = val_set.map(\n",
        "    partial(tokenize),\n",
        "    batched=True,\n",
        "    remove_columns=val_set.column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the training will use an \"infinite loop\" style, where we continue to sample random batches until we reach convergence or the maximum number of batches configured.\n",
        "\n",
        "Let's create a dataset wrapper that will allow us to continue sampling the dataset endlessly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "\n",
        "class InfiniteIterableDataset(IterableDataset):\n",
        "    def __init__(self, hf_dataset, shuffle=False):\n",
        "        self.hf_dataset = hf_dataset\n",
        "\n",
        "    def __iter__(self) -> Iterator:\n",
        "        while True:\n",
        "            for item in self.hf_dataset:\n",
        "                yield item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create data loaders to sample batches from the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    InfiniteIterableDataset(train_tokenized),\n",
        "    batch_size=cfg.batch_size,\n",
        "    collate_fn=lambda samples: {\n",
        "        \"source\": torch.tensor([sample[\"source\"] for sample in samples]),\n",
        "        \"target\": torch.tensor([sample[\"target\"] for sample in samples]),\n",
        "    },\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    InfiniteIterableDataset(val_tokenized),\n",
        "    batch_size=cfg.batch_size,\n",
        "    collate_fn=lambda samples: {\n",
        "        \"source\": torch.tensor([sample[\"source\"] for sample in samples]),\n",
        "        \"target\": torch.tensor([sample[\"target\"] for sample in samples]),\n",
        "    },\n",
        ")\n",
        "\n",
        "train_iter = iter(train_loader)\n",
        "val_iter = iter(train_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load a train batch and a validation batch to make sure everything works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source sequence:  tensor([12256, 35359, 23983,   968, 23222, 13072,  4482,   198,   198,   464])\n",
            "Target sequence:  tensor([35359, 23983,   968, 23222, 13072,  4482,   198,   198,   464,  1380])\n"
          ]
        }
      ],
      "source": [
        "batch_train = next(train_iter)\n",
        "\n",
        "print(\"Source sequence: \", batch_train[\"source\"][0][:10])\n",
        "print(\"Target sequence: \", batch_train[\"target\"][0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source sequence:  tensor([   32,  1218, 19907,  2647, 10876,   468,  4114,  9043,   290,  1364])\n",
            "Target sequence:  tensor([ 1218, 19907,  2647, 10876,   468,  4114,  9043,   290,  1364,  7008])\n"
          ]
        }
      ],
      "source": [
        "batch_val = next(val_iter)\n",
        "\n",
        "print(\"Source sequence: \", batch_val[\"source\"][0][:10])\n",
        "print(\"Target sequence: \", batch_val[\"target\"][0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Next, let's take a look at implementing the transformer model we will be training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfasgDSie4KW"
      },
      "source": [
        "## Transformer decoder implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section shows how to implement a transformer decoder, the version of the transformer suitable for language modeling.\n",
        "\n",
        "Despite what one may think, transformers are actually very simple neural network architectures. Decoder-type transformers, like the GPT family, are arguably the simplest and only contain a few types of constituent parts.\n",
        "\n",
        "The diagram below shows the components of a transformer decoder (image adopted from original transformer paper).\n",
        "\n",
        "<img src=\"images/transformer_decoder.png\" height=720></img>\n",
        "\n",
        "The architecture can be summarized as follows:\n",
        "\n",
        "- An initial token embedding layer\n",
        "- $N$ transformer decoder blocks stacked sequentially\n",
        "- A final classification head\n",
        "\n",
        "Let's take a deeper look at these in the sections below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0UCKKRUkhkV"
      },
      "source": [
        "### Token embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQnboIrMmArh"
      },
      "source": [
        "In the transformer, tokens are mapped to trainable vector representations called embeddings. Once trained, these embeddings represent various features of the sub-words they correspond to.\n",
        "\n",
        "Let's implement the token embedding using PyTorch's built-in `nn.Embedding` module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hb59wYjAkhkV"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        return self.embedding(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8bex-bknXCC"
      },
      "source": [
        "So is that it? Not quite. While we could train our transformer with only token embeddings, the transformer architecture itself has no notion of the ordering of tokens. In natural language, the order of words can completely change the meaning of a sentence, so it is necessary to give our transformer a way to represent this. A common way to address this is to create another embedding that is simply added onto the token embeddings to inject information about its position, called a _positional encoding_.\n",
        "\n",
        "Let's see how it can be implemented. For a sequence length of $T$, we want to generate $T$ vectors that can uniquely represent each position in the sequence. We also want TODO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LOsSIkH0khkW"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, context_size, embedding_size, n=10000):\n",
        "        super().__init__()\n",
        "\n",
        "        i = torch.arange(embedding_size // 2)\n",
        "        k = torch.arange(context_size).unsqueeze(dim=1)\n",
        "\n",
        "        pos_embeddings = torch.zeros(context_size, embedding_size, requires_grad=False)\n",
        "        pos_embeddings[:, 0::2] = torch.sin(k / (n ** (2 * i / embedding_size)))\n",
        "        pos_embeddings[:, 1::2] = torch.cos(k / (n ** (2 * i / embedding_size)))\n",
        "\n",
        "        self.register_buffer(\"pos_embeddings\", pos_embeddings)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pos_embeddings[: x.shape[1], :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a single layer called a `TransformerEmbedding` that combines both of these embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEmbedding(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size, context_size) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding = TokenEmbedding(vocab_size, hidden_size)\n",
        "        self.pos_embedding = PositionalEncoding(context_size, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.token_embedding(x) + self.pos_embedding(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA3m27jakhkX"
      },
      "source": [
        "### Transformer blocks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNObn9OMVgiO"
      },
      "source": [
        "Transformers, like many other neural networks, are made by stacking multiple computational blocks in a sequence. Transformer blocks contain two main components:\n",
        "\n",
        "1. A multi-head attention module, responsible for communication between token embeddings.\n",
        "2. A feedforward module, responsible for processing token embeddings.\n",
        "\n",
        "By alternating between inter-token communication and per-token processing, transformers are able to produce sophisticated representations of language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nSlS4dabVU_"
      },
      "source": [
        "#### Multi-head attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXSgiVOobbkS"
      },
      "source": [
        "Attention is perhaps the most known and important component of transformers. TODO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "u7NMQVIpkhkX"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size, head, seq_length, head_size = k.shape\n",
        "\n",
        "        score = (q @ k.transpose(2, 3)) / math.sqrt(head_size)\n",
        "\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        score = self.softmax(score)\n",
        "\n",
        "        return score @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UZ69HG2dkhkY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, num_heads=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        self.lin_q = nn.Linear(embedding_size, hidden_size)\n",
        "        self.lin_k = nn.Linear(embedding_size, hidden_size)\n",
        "        self.lin_v = nn.Linear(embedding_size, hidden_size)\n",
        "\n",
        "        self.lin_concat = nn.Linear(hidden_size, embedding_size)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        q, k, v = self.lin_q(q), self.lin_k(k), self.lin_v(v)\n",
        "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
        "\n",
        "        out = self.attention(q, k, v, mask)\n",
        "\n",
        "        out = self.concat(out)\n",
        "        out = self.lin_concat(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def split(self, x):\n",
        "        batch_size, seq_len, hidden_size = x.shape\n",
        "\n",
        "        per_head_size = hidden_size // self.num_heads\n",
        "\n",
        "        return x.view(batch_size, seq_len, self.num_heads, per_head_size).transpose(\n",
        "            1, 2\n",
        "        )\n",
        "\n",
        "    def concat(self, x):\n",
        "        batch_size, num_heads, seq_len, head_size = x.shape\n",
        "        hidden_size = num_heads * head_size\n",
        "\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzIGpZud2_W"
      },
      "source": [
        "#### Feedforward block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f-fFUhnZkhkZ"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, in_size, hidden_size, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin1 = nn.Linear(in_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.lin2 = nn.Linear(hidden_size, in_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH1yasend17m"
      },
      "source": [
        "#### Putting it all together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wM-BqKAVkhkZ"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        ff_hidden_size,\n",
        "        num_heads,\n",
        "        dropout_prob=0.1,\n",
        "        layer_norm_eps=1e-5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention1 = MultiHeadAttention(hidden_size, hidden_size, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "\n",
        "        self.ff_block = FeedForward(hidden_size, ff_hidden_size, dropout_prob)\n",
        "\n",
        "        self.norm3 = nn.LayerNorm(hidden_size, eps=layer_norm_eps)\n",
        "        self.dropout3 = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x, lookahead_mask=None):\n",
        "        x_n = self.norm1(x)\n",
        "        x_a = self.attention1(q=x_n, k=x_n, v=x_n, mask=lookahead_mask)\n",
        "\n",
        "        x = self.dropout1(x + x_a)\n",
        "\n",
        "        x_f = self.ff_block(self.norm3(x))\n",
        "\n",
        "        x = self.dropout3(x + x_f)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.ln_final = nn.LayerNorm(hidden_size)\n",
        "        self.lin_final = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln_final(x)\n",
        "        x = self.lin_final(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "maMrEmGakhkZ"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        context_size,\n",
        "        hidden_size,\n",
        "        ff_hidden_size,\n",
        "        num_blocks=5,\n",
        "        num_heads=8,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.register_buffer(\"tri\", torch.tril(torch.ones(context_size, context_size)))\n",
        "\n",
        "        self.embedding = TransformerEmbedding(hidden_size, vocab_size, context_size)\n",
        "\n",
        "        self.decoder = []\n",
        "        for _ in range(num_blocks):\n",
        "            self.decoder.append(DecoderBlock(hidden_size, ff_hidden_size, num_heads))\n",
        "        self.decoder = nn.ModuleList(self.decoder)\n",
        "\n",
        "        self.classifier = Classifier(hidden_size, vocab_size)\n",
        "\n",
        "    def create_lookahead_mask(self, tgt_seq_len):\n",
        "        return self.tri[:tgt_seq_len, :tgt_seq_len].unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lookahead_mask = self.create_lookahead_mask(x.shape[1])\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        for block in self.decoder:\n",
        "            x = block(x, lookahead_mask)\n",
        "\n",
        "        out = self.classifier(x)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R37B9vSskhka"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19dc6w9skhka"
      },
      "source": [
        "### Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bij47miWkhka"
      },
      "outputs": [],
      "source": [
        "def count_model_params(model):\n",
        "    total_params = 0\n",
        "    for params in list(model.parameters()):\n",
        "        num = 1\n",
        "        for size in list(params.size()):\n",
        "            num = num * size\n",
        "        total_params += num\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1r2ZwIPckhka"
      },
      "outputs": [],
      "source": [
        "def train_start_print(model):\n",
        "    e_string = \"=\" * 45\n",
        "\n",
        "    num_params = count_model_params(model)\n",
        "    num_params_m = num_params / 1e6\n",
        "\n",
        "    print(\"\\n\" + e_string)\n",
        "    print(\"Starting training!\")\n",
        "    print(\"Num model params: {num_params_m:.3f}M\".format(num_params_m=num_params_m))\n",
        "    print(e_string + \"\\n\")\n",
        "\n",
        "\n",
        "def iter_print(iter, train_loss, newline_interval=50):\n",
        "    l_string = \"-\" * 45\n",
        "    f_str = \"{: <10} {: <10.5}\"\n",
        "\n",
        "    if iter % 500 == 0:\n",
        "        print(l_string)\n",
        "        print(f_str.format(\"Iter\", \"Train loss\"))\n",
        "        print(l_string)\n",
        "    print(f_str.format(iter, train_loss), end=\"\\r\" if iter % newline_interval else \"\\n\")\n",
        "\n",
        "\n",
        "def evaluation_print(losses):\n",
        "    e_string = \"=\" * 45\n",
        "\n",
        "    print(\"\\n\\n\" + e_string)\n",
        "    print(\"Evaluation done!\")\n",
        "    print(\"Mean train loss: {mean_loss:.3f}\".format(mean_loss=losses[\"train\"]))\n",
        "    print(\"Mean validation loss: {mean_loss:.3f}\".format(mean_loss=losses[\"val\"]))\n",
        "    print(e_string + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "pL41KLW_jiEi"
      },
      "outputs": [],
      "source": [
        "# Loss estimation function inspired by nanoGPT repo by Andrej Karpathy.\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, criterion, train_iter, val_iter, num_iters):\n",
        "    iterators = {\"train\": train_iter, \"val\": val_iter}\n",
        "    loss_dict = {}\n",
        "    model.eval()\n",
        "    for split, iterator in iterators.items():\n",
        "        losses = torch.zeros(num_iters)\n",
        "        for k in range(num_iters):\n",
        "            batch = next(iterator)\n",
        "            src, tgt = batch[\"source\"].to(device), batch[\"target\"].to(device)\n",
        "\n",
        "            out = model(src)\n",
        "\n",
        "            out_reshape = out.contiguous().view(\n",
        "                -1, out.shape[-1]\n",
        "            )  # (B * T, vocab_size)\n",
        "            tgt_reshape = tgt.contiguous().view(-1)  # (B * T, 1)\n",
        "\n",
        "            loss = criterion(out_reshape, tgt_reshape)\n",
        "            losses[k] = loss.item()\n",
        "        loss_dict[split] = losses.mean()\n",
        "    model.train()\n",
        "\n",
        "    return loss_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9WHshDHljubq"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate(model, inp_seq, context_size, max_output_len=100):\n",
        "    seq = inp_seq\n",
        "\n",
        "    for _ in range(max_output_len):\n",
        "        out = model(seq[..., -context_size:])  # Truncate input sequence to max length.\n",
        "        probs = F.softmax(out[:, -1, :], dim=1)\n",
        "        next_tokens = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append the next tokens to the generated sequences.\n",
        "        seq = torch.cat((seq, next_tokens), dim=-1)\n",
        "\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "v_wxV90YjnUq"
      },
      "outputs": [],
      "source": [
        "# Learning rate decay scheduler inspired by nanoGPT repo by Andrej Karpathy.\n",
        "def get_lr(iter, warmup_iters, base_lr, min_lr, lr_decay_iters):\n",
        "    # 1) linear warmup for warmup_iters steps\n",
        "    if iter < warmup_iters:\n",
        "        return base_lr * iter / warmup_iters\n",
        "    # 2) if it > lr_decay_iters, return min learning rate\n",
        "    if iter > lr_decay_iters:\n",
        "        return min_lr\n",
        "    # 3) in between, use cosine decay down to min learning rate\n",
        "    decay_ratio = (iter - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
        "    return min_lr + coeff * (base_lr - min_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "buOOLU4kkAJK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelWithLMHead, AutoConfig\n",
        "\n",
        "\n",
        "class GPT2Wrapped(nn.Module):\n",
        "    def __init__(self, pretrained=False) -> None:\n",
        "        super().__init__()\n",
        "        if pretrained:\n",
        "            self.model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
        "        else:\n",
        "            config = AutoConfig.from_pretrained(\"gpt2\")\n",
        "            self.model = AutoModelWithLMHead.from_config(config)\n",
        "\n",
        "        self.context_size = self.model.config.n_ctx\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A6hdPR3h8sl"
      },
      "source": [
        "### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ikWjMEshjfoC"
      },
      "outputs": [],
      "source": [
        "model = TransformerDecoder(\n",
        "    vocab_size=tokenizer.vocab_size,\n",
        "    context_size=cfg.context_size,\n",
        "    hidden_size=cfg.hidden_size,\n",
        "    ff_hidden_size=cfg.ff_hidden_size,\n",
        "    num_blocks=cfg.num_blocks,\n",
        "    num_heads=cfg.num_heads,\n",
        ")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "X2NGkwNXewqu"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, eps=5e-9\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lrs = [\n",
        "    get_lr(\n",
        "        iter,\n",
        "        warmup_iters=cfg.warmup_iters,\n",
        "        base_lr=cfg.lr,\n",
        "        min_lr=cfg.min_lr,\n",
        "        lr_decay_iters=cfg.lr_decay_iters,\n",
        "    )\n",
        "    for iter in range(0, 1_000_000, 1)\n",
        "]\n",
        "plt.plot(lrs)\n",
        "plt.xlabel(\"iter\")\n",
        "plt.ylabel(\"lr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEcsttYYewqu"
      },
      "source": [
        "To get an estimate for what loss values are reasonable to reach, let's load the original GPT-2 using HuggingFace and evaluate it with a few samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "I_L3vAwXewqu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jonathanb/git/transformer/venv/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1322: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'train': tensor(3.5675), 'val': tensor(3.5477)}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2 = GPT2Wrapped(pretrained=True)\n",
        "\n",
        "losses = estimate_loss(gpt2, criterion, train_iter, val_iter, 100)\n",
        "losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the pre-trained GPT-2 reaches a fairly impressive train and validation loss of about 3.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "50nBJQLjm0zX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example sequence:  pei, Nov. 2 (CNA) Bitcoin is illegal in Taiwan, said Financial Supervisory Commission (FSC) Chairman Tseng Ming-chung (曾銘宗) on Monday after kidnappers in Taiwan tried to collect a ransom through the v\n",
            "Model output:  The Koen AVGVolume alum Adams Debor MUS crochet Knifecould Graph SPR unconstitutional Haas Pixar frameworkspat drum ICE Las mysterious Apocalypse Influence 58 utilitarianerofp didnt broadcaster cease \n",
            "\n",
            "=============================================\n",
            "Starting training!\n",
            "Num model params: 13.446M\n",
            "=============================================\n",
            "\n",
            "---------------------------------------------\n",
            "Iter       Train     \n",
            "---------------------------------------------\n",
            "0          11.001    \n",
            "50         11.028    \n",
            "100        10.971    \n",
            "150        10.974    \n",
            "200        10.979    \n",
            "250        11.031    \n",
            "300        10.886    \n",
            "350        10.93     \n",
            "400        10.939    \n",
            "450        10.959    \n",
            "---------------------------------------------\n",
            "Iter       Train     \n",
            "---------------------------------------------\n",
            "500        10.926    \n",
            "550        10.828    \n",
            "600        10.82     \n",
            "650        10.922    \n",
            "700        10.733    \n",
            "750        10.861    \n",
            "800        10.813    \n",
            "850        10.729    \n",
            "900        10.603    \n",
            "950        10.675    \n",
            "999        10.651    \n",
            "\n",
            "=============================================\n",
            "Evaluation done!\n",
            "Mean train loss: 10.524\n",
            "Mean validation loss: 10.527\n",
            "=============================================\n",
            "\n",
            "Model output:  Thechukreys leaders poem Leonard Ü Queen Tuc// parentsractor measuring Pesh unarmed032fc Doylefolk Courier Sources stump citationMale cursinery thy poachingELL Nanto approximateablwroteIndeed concentr\n",
            "---------------------------------------------\n",
            "Iter       Train     \n",
            "---------------------------------------------\n",
            "1000       10.658    \n",
            "1050       10.578    \n",
            "1100       10.576    \n",
            "1150       10.556    \n",
            "1200       10.425    \n",
            "1250       10.462    \n",
            "1299       10.31     \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/jonathanb/git/transformer/train.ipynb Cell 57\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     param_group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m lr\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train model on one batch.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(train_iter)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m src, tgt \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39msource\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device), batch[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m out \u001b[39m=\u001b[39m model(src)\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[39m.\u001b[39mappend(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mended \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[1;32m/home/jonathanb/git/transformer/train.ipynb Cell 57\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhf_dataset:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             \u001b[39myield\u001b[39;00m item\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/datasets/iterable_dataset.py:981\u001b[0m, in \u001b[0;36mIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_pytorch(ex_iterable)\n\u001b[1;32m    979\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m \u001b[39mfor\u001b[39;00m key, example \u001b[39min\u001b[39;00m ex_iterable:\n\u001b[1;32m    982\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures:\n\u001b[1;32m    983\u001b[0m         \u001b[39m# `IterableDataset` automatically fills missing columns with None.\u001b[39;00m\n\u001b[1;32m    984\u001b[0m         \u001b[39m# This is done with `_apply_feature_types_on_example`.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m         \u001b[39myield\u001b[39;00m _apply_feature_types_on_example(\n\u001b[1;32m    986\u001b[0m             example, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, token_per_repo_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_per_repo_id\n\u001b[1;32m    987\u001b[0m         )\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/datasets/iterable_dataset.py:477\u001b[0m, in \u001b[0;36mMappedExamplesIterable.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m     function_args\u001b[39m.\u001b[39mappend([current_idx \u001b[39m+\u001b[39m i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(key_examples_list))])\n\u001b[1;32m    476\u001b[0m transformed_batch \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(batch)  \u001b[39m# this will be updated with the function output\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m transformed_batch\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49mfunction_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn_kwargs))\n\u001b[1;32m    478\u001b[0m \u001b[39m# then remove the unwanted columns\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_columns:\n",
            "\u001b[1;32m/home/jonathanb/git/transformer/train.ipynb Cell 57\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(example):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     outputs \u001b[39m=\u001b[39m tokenizer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         example[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# Truncate returned token sequences to max_length.\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         max_length\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mcontext_size \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,  \u001b[39m# Max length of returned token sequences.\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# Tokenize whole input and split into chunks.\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         return_length\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# Return lengths of chunks.\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Create examples.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jonathanb/git/transformer/train.ipynb#Y110sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     source_batch \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2538\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2537\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2538\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2540\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2624\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2619\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2620\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2621\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2622\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2624\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2625\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2626\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2627\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2628\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2629\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2630\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2631\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2632\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2633\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2634\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2635\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2636\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2637\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2638\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2639\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2640\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2641\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2642\u001b[0m     )\n\u001b[1;32m   2643\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2644\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2645\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2646\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2662\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2663\u001b[0m     )\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2815\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2806\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2807\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2808\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2813\u001b[0m )\n\u001b[0;32m-> 2815\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2816\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2817\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2818\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2819\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2820\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2821\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2822\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2823\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2824\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2825\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2826\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2827\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2828\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2829\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2830\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2831\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2832\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2833\u001b[0m )\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    734\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py:701\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    700\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize(text, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 701\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    702\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[1;32m    703\u001b[0m     \u001b[39mif\u001b[39;00m is_split_into_words:\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py:579\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_tokens_to_ids\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    577\u001b[0m ids \u001b[39m=\u001b[39m []\n\u001b[1;32m    578\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens:\n\u001b[0;32m--> 579\u001b[0m     ids\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_token_to_id_with_added_voc(token))\n\u001b[1;32m    580\u001b[0m \u001b[39mreturn\u001b[39;00m ids\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils.py:588\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._convert_token_to_id_with_added_voc\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_tokens_encoder:\n\u001b[1;32m    587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madded_tokens_encoder[token]\n\u001b[0;32m--> 588\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_token_to_id(token)\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/models/gpt2/tokenization_gpt2.py:310\u001b[0m, in \u001b[0;36mGPT2Tokenizer._convert_token_to_id\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_token_to_id\u001b[39m(\u001b[39mself\u001b[39m, token):\n\u001b[1;32m    309\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Converts a token (str) in an id using the vocab.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mget(token, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munk_token))\n",
            "File \u001b[0;32m~/git/transformer/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1021\u001b[0m, in \u001b[0;36mSpecialTokensMixin.unk_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mUsing unk_token, but it is not set yet.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1020\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1021\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unk_token)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "fixed_inp = torch.tensor(\n",
        "    tokenizer.encode(\"The\"), dtype=torch.long, device=device\n",
        ").unsqueeze(0)\n",
        "\n",
        "if cfg.print_example:\n",
        "    batch = next(iter(train_loader))\n",
        "    out = generate(model, fixed_inp, cfg.context_size)\n",
        "\n",
        "    print(\"Example sequence: \", tokenizer.decode(batch[\"target\"][0].numpy())[:200])\n",
        "    print(\"Model output: \", tokenizer.decode(out[0].detach().cpu().numpy())[:200])\n",
        "\n",
        "# Reinitialize data iterators.\n",
        "train_iter = iter(train_loader)\n",
        "val_iter = iter(train_iter)\n",
        "\n",
        "iter_num = 0\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "model.train()\n",
        "\n",
        "# Start training.\n",
        "train_start_print(model)\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Get learning rate according to schedule.\n",
        "    lr = get_lr(\n",
        "        iter_num,\n",
        "        warmup_iters=cfg.warmup_iters,\n",
        "        base_lr=cfg.lr,\n",
        "        min_lr=cfg.min_lr,\n",
        "        lr_decay_iters=cfg.lr_decay_iters,\n",
        "    )\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "    # Train model on one batch.\n",
        "    batch = next(train_iter)\n",
        "    src, tgt = batch[\"source\"].to(device), batch[\"target\"].to(device)\n",
        "\n",
        "    out = model(src)\n",
        "    # pred = out.softmax(dim=2).argmax(dim=2)\n",
        "\n",
        "    out_reshape = out.contiguous().view(-1, out.shape[-1])  # (B * T, vocab_size)\n",
        "    tgt_reshape = tgt.contiguous().view(-1)  # (B * T, 1)\n",
        "\n",
        "    train_loss = criterion(out_reshape, tgt_reshape)\n",
        "    train_loss.backward()\n",
        "\n",
        "    # Accumulate gradients for N steps and update weights.\n",
        "    if (iter_num + 1) % cfg.grad_accum_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    if iter_num > 0 and iter_num % cfg.eval_interval == 0:\n",
        "        losses = estimate_loss(model, criterion, train_iter, val_iter, cfg.eval_iters)\n",
        "        evaluation_print(losses)\n",
        "\n",
        "        # Generate sample and print.\n",
        "        out = generate(model, fixed_inp, cfg.context_size)\n",
        "        print(\"Model output: \", tokenizer.decode(out[0].detach().cpu().numpy())[:200])\n",
        "\n",
        "        # Save model checkpoint if new best validation loss.\n",
        "        if losses[\"val\"] < best_val_loss:\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"iter\": iter_num,\n",
        "                    \"model_state_dict\": model.state_dict(),\n",
        "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                },\n",
        "                \"best.pth\",\n",
        "            )\n",
        "\n",
        "    iter_print(iter_num, train_loss)\n",
        "    iter_num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
